# Speed vs Time scatter plot
    sample_data = passages_df.sample(min(1000, len(passages_df)))  # Sample for performance
    scatter = axes[1, 0].scatter(sample_data['timestamp'], sample_data['speed_mph'], alpha=0.6, c=sample_data['speed_mph'], cmap='viridis', s=20)
    axes[1, 0].set_title('Speed vs Time')\n    axes[1, 0].set_xlabel('Time')\n    axes[1, 0].set_ylabel('Speed (mph)')\n    axes[1, 0].tick_params(axis='x', rotation=45)\n    plt.colorbar(scatter, ax=axes[1, 0], label='Speed (mph)')\n    \n    # Traffic volume over time\n    daily_volumes = passages_df.groupby(passages_df['timestamp'].dt.date).size()\n    axes[1, 1].plot(daily_volumes.index, daily_volumes.values, linewidth=2, marker='o', markersize=4, color='purple')\n    axes[1, 1].set_title('Daily Traffic Volume')\n    axes[1, 1].set_xlabel('Date')\n    axes[1, 1].set_ylabel('Vehicle Count')\n    axes[1, 1].tick_params(axis='x', rotation=45)\n    axes[1, 1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. IVDC Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IVDC Performance Analysis\n",
    "if 'ivdc_success' in passages_df.columns:\n",
    "    ivdc_metrics = passage_analyzer.analyze_ivdc_performance(passages_df)\n",
    "    \n",
    "    print(\"üì° IVDC Performance Analysis:\")\n",
    "    print(\"=\" * 30)\n",
    "    print(f\"Success rate: {ivdc_metrics.success_rate:.2f}%\")\n",
    "    print(f\"Average response time: {ivdc_metrics.avg_response_time:.1f} ms\")\n",
    "    print(f\"Error count: {ivdc_metrics.error_count}\")\n",
    "    print(f\"Timeout count: {ivdc_metrics.timeout_count}\")\n",
    "    print(f\"Data quality score: {ivdc_metrics.data_quality_score:.1f}/100\")\n",
    "    \n",
    "    # IVDC success by lane\n",
    "    lane_ivdc = passages_df.groupby('lane_id')['ivdc_success'].agg(['mean', 'count']).round(3)\n",
    "    lane_ivdc.columns = ['Success_Rate', 'Total_Transactions']\n",
    "    lane_ivdc['Success_Rate'] *= 100\n",
    "    print(\"\\nIVDC Performance by Lane:\")\n",
    "    print(lane_ivdc)\n",
    "    \n",
    "    # IVDC success by hour\n",
    "    hourly_ivdc = passages_df.groupby(passages_df['timestamp'].dt.hour)['ivdc_success'].mean() * 100\n",
    "    print(f\"\\nBest IVDC hour: {hourly_ivdc.idxmax()}:00 ({hourly_ivdc.max():.1f}%)\")\n",
    "    print(f\"Worst IVDC hour: {hourly_ivdc.idxmin()}:00 ({hourly_ivdc.min():.1f}%)\")\n",
    "\n",
    "# Processing time analysis\n",
    "if 'processing_time_ms' in passages_df.columns:\n",
    "    print(\"\\n‚è±Ô∏è Processing Time Analysis:\")\n",
    "    print(\"=\" * 28)\n",
    "    print(f\"Average processing time: {passages_df['processing_time_ms'].mean():.1f} ms\")\n",
    "    print(f\"Median processing time: {passages_df['processing_time_ms'].median():.1f} ms\")\n",
    "    print(f\"95th percentile: {passages_df['processing_time_ms'].quantile(0.95):.1f} ms\")\n",
    "    print(f\"Max processing time: {passages_df['processing_time_ms'].max():.1f} ms\")\n",
    "    \n",
    "    # Processing time by vehicle type\n",
    "    type_processing = passages_df.groupby('vehicle_type')['processing_time_ms'].agg(['mean', 'std']).round(1)\n",
    "    print(\"\\nProcessing Time by Vehicle Type:\")\n",
    "    print(type_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IVDC Performance Visualizations\n",
    "if 'ivdc_success' in passages_df.columns and 'processing_time_ms' in passages_df.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('IVDC Performance Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # IVDC success rate by hour\n",
    "    hourly_ivdc = passages_df.groupby(passages_df['timestamp'].dt.hour)['ivdc_success'].mean() * 100\n",
    "    axes[0, 0].plot(hourly_ivdc.index, hourly_ivdc.values, marker='o', linewidth=2, markersize=6, color='green')\n",
    "    axes[0, 0].axhline(y=95, color='red', linestyle='--', alpha=0.7, label='95% Target')\n",
    "    axes[0, 0].set_title('IVDC Success Rate by Hour')\n",
    "    axes[0, 0].set_xlabel('Hour of Day')\n",
    "    axes[0, 0].set_ylabel('Success Rate (%)')\n",
    "    axes[0, 0].set_ylim([85, 100])\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # IVDC success by lane\n",
    "    lane_ivdc = passages_df.groupby('lane_id')['ivdc_success'].mean() * 100\n",
    "    axes[0, 1].bar(lane_ivdc.index, lane_ivdc.values, color='lightblue')\n",
    "    axes[0, 1].axhline(y=95, color='red', linestyle='--', alpha=0.7, label='95% Target')\n",
    "    axes[0, 1].set_title('IVDC Success Rate by Lane')\n",
    "    axes[0, 1].set_xlabel('Lane ID')\n",
    "    axes[0, 1].set_ylabel('Success Rate (%)')\n",
    "    axes[0, 1].set_ylim([85, 100])\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Processing time distribution\n",
    "    axes[1, 0].hist(passages_df['processing_time_ms'], bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[1, 0].axvline(passages_df['processing_time_ms'].mean(), color='red', linestyle='--', linewidth=2, \n",
    "                       label=f'Mean: {passages_df[\"processing_time_ms\"].mean():.1f} ms')\n",
    "    axes[1, 0].set_title('Processing Time Distribution')\n",
    "    axes[1, 0].set_xlabel('Processing Time (ms)')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Processing time by vehicle type\n",
    "    type_processing = passages_df.groupby('vehicle_type')['processing_time_ms'].mean().sort_values()\n",
    "    axes[1, 1].barh(range(len(type_processing)), type_processing.values, color='lightcoral')\n",
    "    axes[1, 1].set_title('Average Processing Time by Vehicle Type')\n",
    "    axes[1, 1].set_xlabel('Processing Time (ms)')\n",
    "    axes[1, 1].set_yticks(range(len(type_processing)))\n",
    "    axes[1, 1].set_yticklabels(type_processing.index)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(type_processing.values):\n",
    "        axes[1, 1].text(v + 5, i, f'{v:.1f}', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Lane Efficiency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lane efficiency analysis\n",
    "lane_efficiency = passage_analyzer.calculate_lane_efficiency(passages_df)\n",
    "\n",
    "if not lane_efficiency.empty:\n",
    "    print(\"üõ£Ô∏è Lane Efficiency Analysis:\")\n",
    "    print(\"=\" * 28)\n",
    "    print(lane_efficiency[['lane_id', 'vehicle_id_count', 'speed_mph_mean', 'efficiency_score']].round(2))\n",
    "    \n",
    "    # Best and worst performing lanes\n",
    "    if 'efficiency_score' in lane_efficiency.columns:\n",
    "        best_lane = lane_efficiency.loc[lane_efficiency['efficiency_score'].idxmax()]\n",
    "        worst_lane = lane_efficiency.loc[lane_efficiency['efficiency_score'].idxmin()]\n",
    "        \n",
    "        print(f\"\\nüèÜ Best performing lane: {best_lane['lane_id']} (Score: {best_lane['efficiency_score']:.1f})\")\n",
    "        print(f\"üìâ Worst performing lane: {worst_lane['lane_id']} (Score: {worst_lane['efficiency_score']:.1f})\")\n",
    "\n",
    "# Lane utilization over time\n",
    "lane_hourly = passages_df.groupby([passages_df['timestamp'].dt.hour, 'lane_id']).size().unstack(fill_value=0)\n",
    "\n",
    "# Visualize lane efficiency\n",
    "if not lane_efficiency.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Lane Efficiency Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Lane utilization\n",
    "    lane_counts = passages_df['lane_id'].value_counts().sort_index()\n",
    "    axes[0, 0].bar(lane_counts.index, lane_counts.values, color='steelblue')\n",
    "    axes[0, 0].set_title('Vehicle Count by Lane')\n",
    "    axes[0, 0].set_xlabel('Lane ID')\n",
    "    axes[0, 0].set_ylabel('Vehicle Count')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Lane efficiency scores\n",
    "    if 'efficiency_score' in lane_efficiency.columns:\n",
    "        axes[0, 1].bar(lane_efficiency['lane_id'], lane_efficiency['efficiency_score'], color='lightgreen')\n",
    "        axes[0, 1].set_title('Lane Efficiency Scores')\n",
    "        axes[0, 1].set_xlabel('Lane ID')\n",
    "        axes[0, 1].set_ylabel('Efficiency Score')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Lane utilization heatmap\n",
    "    im = axes[1, 0].imshow(lane_hourly.T, aspect='auto', cmap='YlOrRd')\n",
    "    axes[1, 0].set_title('Lane Utilization by Hour Heatmap')\n",
    "    axes[1, 0].set_xlabel('Hour of Day')\n",
    "    axes[1, 0].set_ylabel('Lane ID')\n",
    "    axes[1, 0].set_xticks(range(0, 24, 2))\n",
    "    axes[1, 0].set_xticklabels(range(0, 24, 2))\n",
    "    axes[1, 0].set_yticks(range(len(lane_hourly.columns)))\n",
    "    axes[1, 0].set_yticklabels(lane_hourly.columns)\n",
    "    plt.colorbar(im, ax=axes[1, 0], label='Vehicle Count')\n",
    "    \n",
    "    # Speed comparison by lane\n",
    "    if 'speed_mph_mean' in lane_efficiency.columns:\n",
    "        axes[1, 1].bar(lane_efficiency['lane_id'], lane_efficiency['speed_mph_mean'], color='coral')\n",
    "        axes[1, 1].set_title('Average Speed by Lane')\n",
    "        axes[1, 1].set_xlabel('Lane ID')\n",
    "        axes[1, 1].set_ylabel('Average Speed (mph)')\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, (lane, speed) in enumerate(zip(lane_efficiency['lane_id'], lane_efficiency['speed_mph_mean'])):\n",
    "            axes[1, 1].text(i, speed + 1, f'{speed:.1f}', ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect traffic anomalies\n",
    "anomalies = passage_analyzer.detect_traffic_anomalies(passages_df)\n",
    "\n",
    "if not anomalies.empty:\n",
    "    print(\"üö® Traffic Anomaly Detection:\")\n",
    "    print(\"=\" * 29)\n",
    "    \n",
    "    anomaly_summary = anomalies['anomaly_type'].value_counts()\n",
    "    print(\"Anomaly Types:\")\n",
    "    for anomaly_type, count in anomaly_summary.items():\n",
    "        print(f\"  {anomaly_type}: {count}\")\n",
    "    \n",
    "    print(f\"\\nTotal anomalies detected: {anomalies['is_anomaly'].sum()}\")\n",
    "    print(f\"Anomaly rate: {(anomalies['is_anomaly'].sum() / len(anomalies) * 100):.2f}%\")\n",
    "    \n",
    "    # Show most significant anomalies\n",
    "    significant_anomalies = anomalies[anomalies['is_anomaly']].nlargest(5, 'z_score')\n",
    "    print(\"\\nüîç Most Significant Anomalies:\")\n",
    "    print(significant_anomalies[['timestamp', 'vehicle_count', 'z_score', 'anomaly_type']].round(2))\n",
    "\n",
    "# Speed outliers\n",
    "if 'speed_mph' in passages_df.columns:\n",
    "    speed_outliers = data_processor.detect_outliers(passages_df[['speed_mph']], method='iqr')\n",
    "    speed_outlier_count = speed_outliers['speed_mph_outlier'].sum()\n",
    "    \n",
    "    print(f\"\\nüèÉ Speed Outliers:\")\n",
    "    print(f\"Speed outliers detected: {speed_outlier_count}\")\n",
    "    print(f\"Outlier rate: {(speed_outlier_count / len(passages_df) * 100):.2f}%\")\n",
    "    \n",
    "    if speed_outlier_count > 0:\n",
    "        extreme_speeds = passages_df[speed_outliers['speed_mph_outlier']]['speed_mph']\n",
    "        print(f\"Min outlier speed: {extreme_speeds.min():.1f} mph\")\n",
    "        print(f\"Max outlier speed: {extreme_speeds.max():.1f} mph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly visualizations\n",
    "if not anomalies.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Anomaly Detection Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Traffic volume with anomalies highlighted\n",
    "    axes[0, 0].plot(anomalies['timestamp'], anomalies['vehicle_count'], linewidth=1, alpha=0.7, color='blue', label='Normal')\n",
    "    anomaly_data = anomalies[anomalies['is_anomaly']]\n",
    "    axes[0, 0].scatter(anomaly_data['timestamp'], anomaly_data['vehicle_count'], \n",
    "                       color='red', s=50, alpha=0.8, label=f'Anomalies ({len(anomaly_data)})', zorder=5)\n",
    "    axes[0, 0].set_title('Traffic Volume with Anomalies')\n",
    "    axes[0, 0].set_xlabel('Time')\n",
    "    axes[0, 0].set_ylabel('Vehicle Count')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Z-score distribution\n",
    "    axes[0, 1].hist(anomalies['z_score'], bins=50, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "    axes[0, 1].axvline(2, color='red', linestyle='--', label='Anomaly Threshold (¬±2)')\n",
    "    axes[0, 1].axvline(-2, color='red', linestyle='--')\n",
    "    axes[0, 1].set_title('Z-Score Distribution')\n",
    "    axes[0, 1].set_xlabel('Z-Score')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Anomalies by hour\n",
    "    if len(anomaly_data) > 0:\n",
    "        hourly_anomalies = anomaly_data.groupby(anomaly_data['timestamp'].dt.hour).size()\n",
    "        axes[1, 0].bar(hourly_anomalies.index, hourly_anomalies.values, color='orange')\n",
    "        axes[1, 0].set_title('Anomalies by Hour of Day')\n",
    "        axes[1, 0].set_xlabel('Hour')\n",
    "        axes[1, 0].set_ylabel('Anomaly Count')\n",
    "        axes[1, 0].set_xticks(range(0, 24, 2))\n",
    "    \n",
    "    # Speed outliers (if available)\n",
    "    if 'speed_mph' in passages_df.columns:\n",
    "        speed_outliers = data_processor.detect_outliers(passages_df[['speed_mph']], method='iqr')\n",
    "        outlier_speeds = passages_df[speed_outliers['speed_mph_outlier']]['speed_mph']\n",
    "        normal_speeds = passages_df[~speed_outliers['speed_mph_outlier']]['speed_mph']\n",
    "        \n",
    "        axes[1, 1].hist([normal_speeds, outlier_speeds], bins=50, alpha=0.7, \n",
    "                        label=['Normal', f'Outliers ({len(outlier_speeds)})'], color=['lightgreen', 'red'])\n",
    "        axes[1, 1].set_title('Speed Distribution with Outliers')\n",
    "        axes[1, 1].set_xlabel('Speed (mph)')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Operational Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate operational insights\n",
    "print(\"üí° Operational Insights & Recommendations:\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "# Traffic patterns\n",
    "peak_hour = passages_df.groupby(passages_df['timestamp'].dt.hour).size().idxmax()\n",
    "peak_count = passages_df.groupby(passages_df['timestamp'].dt.hour).size().max()\n",
    "off_peak_hour = passages_df.groupby(passages_df['timestamp'].dt.hour).size().idxmin()\n",
    "off_peak_count = passages_df.groupby(passages_df['timestamp'].dt.hour).size().min()\n",
    "\n",
    "print(f\"üïê Peak Traffic: {peak_hour}:00 with {peak_count} vehicles\")\n",
    "print(f\"üïê Off-Peak: {off_peak_hour}:00 with {off_peak_count} vehicles\")\n",
    "print(f\"üìä Peak to Off-Peak Ratio: {(peak_count / off_peak_count):.1f}x\")\n",
    "\n",
    "# Vehicle type insights\n",
    "dominant_vehicle = passages_df['vehicle_type'].value_counts().index[0]\n",
    "dominant_percentage = passages_df['vehicle_type'].value_counts(normalize=True).iloc[0] * 100\n",
    "print(f\"\\nüöó Dominant Vehicle Type: {dominant_vehicle} ({dominant_percentage:.1f}%)\")\n",
    "\n",
    "# Speed insights\n",
    "if 'speed_mph' in passages_df.columns:\n",
    "    avg_speed = passages_df['speed_mph'].mean()\n",
    "    speed_variance = passages_df['speed_mph'].std()\n",
    "    print(f\"\\nüèéÔ∏è Average Speed: {avg_speed:.1f} mph (œÉ = {speed_variance:.1f})\")\n",
    "    \n",
    "    if speed_variance > 10:\n",
    "        print(\"‚ö†Ô∏è High speed variance detected - consider speed management measures\")\n",
    "    \n",
    "    # Speed compliance\n",
    "    speed_limit = 65  # Assume 65 mph speed limit\n",
    "    speeding_rate = (passages_df['speed_mph'] > speed_limit).mean() * 100\n",
    "    print(f\"üö® Speeding Rate: {speeding_rate:.1f}% (>{speed_limit} mph)\")\n",
    "\n",
    "# IVDC insights\n",
    "if 'ivdc_success' in passages_df.columns:\n",
    "    ivdc_rate = passages_df['ivdc_success'].mean() * 100\n",
    "    print(f\"\\nüì° IVDC Success Rate: {ivdc_rate:.2f}%\")\n",
    "    \n",
    "    if ivdc_rate < 95:\n",
    "        print(\"‚ö†Ô∏è IVDC performance below 95% - investigate system issues\")\n",
    "    elif ivdc_rate >= 98:\n",
    "        print(\"‚úÖ Excellent IVDC performance\")\n",
    "\n",
    "# Lane utilization insights\n",
    "lane_utilization = passages_df['lane_id'].value_counts()\n",
    "most_used_lane = lane_utilization.index[0]\n",
    "least_used_lane = lane_utilization.index[-1]\n",
    "utilization_ratio = lane_utilization.iloc[0] / lane_utilization.iloc[-1]\n",
    "\n",
    "print(f\"\\nüõ£Ô∏è Lane Utilization:\")\n",
    "print(f\"   Most used: {most_used_lane} ({lane_utilization.iloc[0]:,} vehicles)\")\n",
    "print(f\"   Least used: {least_used_lane} ({lane_utilization.iloc[-1]:,} vehicles)\")\n",
    "print(f\"   Utilization ratio: {utilization_ratio:.1f}x\")\n",
    "\n",
    "if utilization_ratio > 2:\n",
    "    print(\"‚ö†Ô∏è Significant lane imbalance - consider traffic redistribution strategies\")\n",
    "\n",
    "# Weather impact\n",
    "if 'weather_condition' in passages_df.columns and 'speed_mph' in passages_df.columns:\n",
    "    weather_impact = passages_df.groupby('weather_condition')['speed_mph'].mean()\n",
    "    clear_speed = weather_impact.get('Clear', avg_speed)\n",
    "    \n",
    "    print(f\"\\nüå¶Ô∏è Weather Impact on Speed:\")\n",
    "    for condition, speed in weather_impact.items():\n",
    "        impact = ((speed - clear_speed) / clear_speed * 100) if clear_speed > 0 else 0\n",
    "        print(f\"   {condition}: {speed:.1f} mph ({impact:+.1f}%)\")\n",
    "\n",
    "# Data quality insights\n",
    "data_quality_score = quality_report.get('overall_quality_score', 0)\n",
    "print(f\"\\nüìä Data Quality Score: {data_quality_score:.1f}/100\")\n",
    "\n",
    "if data_quality_score >= 90:\n",
    "    print(\"‚úÖ Excellent data quality\")\n",
    "elif data_quality_score >= 80:\n",
    "    print(\"‚úÖ Good data quality\")\n",
    "elif data_quality_score >= 70:\n",
    "    print(\"‚ö†Ô∏è Moderate data quality - minor issues to address\")\n",
    "else:\n",
    "    print(\"‚ùå Poor data quality - significant issues require attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate actionable recommendations\n",
    "print(\"\\nüéØ Actionable Recommendations:\")\n",
    "print(\"=\" * 32)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "# Traffic management recommendations\n",
    "if (peak_count / off_peak_count) > 3:\n",
    "    recommendations.append(\"Implement dynamic pricing during peak hours to distribute traffic\")\n",
    "\n",
    "if utilization_ratio > 2:\n",
    "    recommendations.append(f\"Redistribute traffic from {most_used_lane} to underutilized lanes\")\n",
    "\n",
    "# Speed management\n",
    "if 'speed_mph' in passages_df.columns:\n",
    "    if speeding_rate > 15:\n",
    "        recommendations.append(\"Implement speed enforcement measures - high speeding rate detected\")\n",
    "    \n",
    "    if speed_variance > 15:\n",
    "        recommendations.append(\"Install variable speed limit signs to reduce speed variance\")\n",
    "\n",
    "# IVDC improvements\n",
    "if 'ivdc_success' in passages_df.columns and ivdc_rate < 95:\n",
    "    worst_ivdc_lane = passages_df.groupby('lane_id')['ivdc_success'].mean().idxmin()\n",
    "    recommendations.append(f\"Investigate IVDC issues in {worst_ivdc_lane} - lowest success rate\")\n",
    "\n",
    "# Operational efficiency\n",
    "{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Passage Data Analysis\n",
    "\n",
    "This notebook provides comprehensive analysis of vehicle passage data, including IVDC logs, traffic patterns, and operational insights for toll road management.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data Loading and Setup](#1-data-loading-and-setup)\n",
    "2. [Data Quality Assessment](#2-data-quality-assessment)\n",
    "3. [Basic Passage Statistics](#3-basic-passage-statistics)\n",
    "4. [Traffic Pattern Analysis](#4-traffic-pattern-analysis)\n",
    "5. [Vehicle Type Analysis](#5-vehicle-type-analysis)\n",
    "6. [Speed and Flow Analysis](#6-speed-and-flow-analysis)\n",
    "7. [IVDC Performance Analysis](#7-ivdc-performance-analysis)\n",
    "8. [Lane Efficiency Analysis](#8-lane-efficiency-analysis)\n",
    "9. [Anomaly Detection](#9-anomaly-detection)\n",
    "10. [Operational Insights](#10-operational-insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from passage_analyzer import PassageAnalyzer, IVDCProcessor, TrafficPatternAnalyzer\n",
    "from utils import DataProcessor, ValidationUtils, DateTimeUtils\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")\n",
    "print(f\"Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzers\n",
    "passage_analyzer = PassageAnalyzer()\n",
    "ivdc_processor = IVDCProcessor()\n",
    "traffic_analyzer = TrafficPatternAnalyzer()\n",
    "data_processor = DataProcessor()\n",
    "validator = ValidationUtils()\n",
    "\n",
    "# Load passage data\n",
    "try:\n",
    "    # Try loading from Excel first, then CSV\n",
    "    try:\n",
    "        passages_df = pd.read_excel('../data/raw/passages.xlsx')\n",
    "        print(\"üìä Loaded data from Excel file\")\n",
    "    except:\n",
    "        passages_df = pd.read_csv('../data/raw/passages.csv')\n",
    "        print(\"üìä Loaded data from CSV file\")\n",
    "    \n",
    "    print(f\"Dataset shape: {passages_df.shape}\")\n",
    "    print(f\"Date range: {passages_df['timestamp'].min()} to {passages_df['timestamp'].max()}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è No passage data file found. Generating sample data...\")\n",
    "    # Generate sample data for demonstration\n",
    "    np.random.seed(42)\n",
    "    dates = pd.date_range(start='2024-01-01', end='2024-01-31', freq='5T')\n",
    "    \n",
    "    passages_data = []\n",
    "    for i, date in enumerate(dates):\n",
    "        hour = date.hour\n",
    "        # More traffic during rush hours\n",
    "        base_traffic = 2 if 7 <= hour <= 9 or 17 <= hour <= 19 else 1\n",
    "        vehicle_count = max(0, np.random.poisson(base_traffic))\n",
    "        \n",
    "        for j in range(vehicle_count):\n",
    "            passages_data.append({\n",
    "                'timestamp': date + timedelta(minutes=np.random.randint(0, 5)),\n",
    "                'vehicle_id': f\"V{i:06d}{j:02d}\",\n",
    "                'lane_id': np.random.choice(['Lane_1', 'Lane_2', 'Lane_3', 'Lane_4']),\n",
    "                'vehicle_type': np.random.choice(['Car', 'Truck', 'Bus', 'Motorcycle'], p=[0.7, 0.2, 0.05, 0.05]),\n",
    "                'speed_mph': np.random.normal(65, 10),\n",
    "                'length_ft': np.random.uniform(12, 65),\n",
    "                'weight_lbs': np.random.uniform(2000, 40000),\n",
    "                'ivdc_success': np.random.random() > 0.05,\n",
    "                'etc_tag_id': f\"ETC{np.random.randint(100000, 999999)}\" if np.random.random() > 0.3 else None,\n",
    "                'image_quality': np.random.choice(['Excellent', 'Good', 'Fair', 'Poor'], p=[0.6, 0.25, 0.1, 0.05]),\n",
    "                'weather_condition': np.random.choice(['Clear', 'Rain', 'Fog'], p=[0.7, 0.2, 0.1]),\n",
    "                'violation': np.random.random() < 0.02,\n",
    "                'processing_time_ms': max(50, np.random.normal(150, 30))\n",
    "            })\n",
    "    \n",
    "    passages_df = pd.DataFrame(passages_data)\n",
    "    print(f\"üìä Generated sample dataset with shape: {passages_df.shape}\")\n",
    "\n",
    "# Display basic info\n",
    "passages_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate data format\n",
    "print(\"üîç Data Validation Results:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "is_valid = validator.validate_passage_data(passages_df)\n",
    "print(f\"Data validation passed: {is_valid}\")\n",
    "\n",
    "# Data quality assessment\n",
    "quality_report = validator.check_data_quality(passages_df)\n",
    "print(f\"\\nüìà Data Quality Score: {quality_report.get('overall_quality_score', 0):.1f}/100\")\n",
    "print(f\"Total rows: {quality_report.get('total_rows', 0):,}\")\n",
    "print(f\"Total columns: {quality_report.get('total_columns', 0)}\")\n",
    "print(f\"Duplicate rows: {quality_report.get('duplicate_rows', 0)}\")\n",
    "\n",
    "# Missing values analysis\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': passages_df.columns,\n",
    "    'Missing_Count': passages_df.isnull().sum(),\n",
    "    'Missing_Percentage': (passages_df.isnull().sum() / len(passages_df) * 100).round(2)\n",
    "})\n",
    "\n",
    "print(\"\\nüîç Missing Data Analysis:\")\n",
    "print(missing_data[missing_data['Missing_Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and basic statistics\n",
    "print(\"üìä Dataset Information:\")\n",
    "print(\"=\" * 25)\n",
    "passages_df.info()\n",
    "\n",
    "print(\"\\nüìà Numerical Columns Statistics:\")\n",
    "print(\"=\" * 35)\n",
    "numeric_cols = ['speed_mph', 'length_ft', 'weight_lbs', 'processing_time_ms']\n",
    "for col in numeric_cols:\n",
    "    if col in passages_df.columns:\n",
    "        print(f\"\\n{col.upper()}:\")\n",
    "        print(passages_df[col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Passage Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basic passage metrics\n",
    "passage_metrics = passage_analyzer.analyze_passages(passages_df)\n",
    "\n",
    "print(\"üöó Passage Analysis Results:\")\n",
    "print(\"=\" * 28)\n",
    "print(f\"Total vehicles: {passage_metrics.total_vehicles:,}\")\n",
    "print(f\"Average speed: {passage_metrics.avg_speed:.1f} mph\")\n",
    "print(f\"Peak hour: {passage_metrics.peak_hour}\")\n",
    "print(f\"Congestion level: {passage_metrics.congestion_level}\")\n",
    "print(f\"IVDC success rate: {passage_metrics.ivdc_success_rate:.1f}%\")\n",
    "print(f\"Violations: {passage_metrics.violation_count}\")\n",
    "print(f\"Revenue estimate: ${passage_metrics.revenue_estimate:,.2f}\")\n",
    "\n",
    "# Daily statistics\n",
    "daily_stats = passage_analyzer.get_daily_statistics(passages_df)\n",
    "print(f\"\\nüìÖ Daily Statistics (Last 10 Days):\")\n",
    "print(\"=\" * 35)\n",
    "print(daily_stats.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Passage Data Overview', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Vehicle count by lane\n",
    "lane_counts = passages_df['lane_id'].value_counts()\n",
    "axes[0, 0].bar(lane_counts.index, lane_counts.values, color='skyblue')\n",
    "axes[0, 0].set_title('Vehicle Count by Lane')\n",
    "axes[0, 0].set_xlabel('Lane ID')\n",
    "axes[0, 0].set_ylabel('Vehicle Count')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Speed distribution\n",
    "if 'speed_mph' in passages_df.columns:\n",
    "    axes[0, 1].hist(passages_df['speed_mph'].dropna(), bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    axes[0, 1].axvline(passages_df['speed_mph'].mean(), color='red', linestyle='--', label=f'Mean: {passages_df[\"speed_mph\"].mean():.1f} mph')\n",
    "    axes[0, 1].set_title('Speed Distribution')\n",
    "    axes[0, 1].set_xlabel('Speed (mph)')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].legend()\n",
    "\n",
    "# Vehicle type distribution\n",
    "type_counts = passages_df['vehicle_type'].value_counts()\n",
    "axes[1, 0].pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[1, 0].set_title('Vehicle Type Distribution')\n",
    "\n",
    "# IVDC success rate by hour\n",
    "if 'ivdc_success' in passages_df.columns:\n",
    "    hourly_ivdc = passages_df.groupby(passages_df['timestamp'].dt.hour)['ivdc_success'].mean() * 100\n",
    "    axes[1, 1].plot(hourly_ivdc.index, hourly_ivdc.values, marker='o', linewidth=2, markersize=6)\n",
    "    axes[1, 1].set_title('IVDC Success Rate by Hour')\n",
    "    axes[1, 1].set_xlabel('Hour of Day')\n",
    "    axes[1, 1].set_ylabel('Success Rate (%)')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Traffic Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze traffic patterns\n",
    "rush_hours = traffic_analyzer.identify_rush_hours(passages_df)\n",
    "seasonal_patterns = traffic_analyzer.analyze_seasonal_patterns(passages_df)\n",
    "\n",
    "print(\"üö¶ Traffic Pattern Analysis:\")\n",
    "print(\"=\" * 29)\n",
    "print(f\"Weekday rush hours: {rush_hours.get('weekday_rush_hours', [])}\")\n",
    "print(f\"Weekend rush hours: {rush_hours.get('weekend_rush_hours', [])}\")\n",
    "print(f\"\\nSeasonal Analysis:\")\n",
    "print(f\"Peak month: {seasonal_patterns.get('peak_month', 'N/A')}\")\n",
    "print(f\"Low month: {seasonal_patterns.get('low_month', 'N/A')}\")\n",
    "print(f\"Seasonal variance: {seasonal_patterns.get('seasonal_variance', 0):.2f}\")\n",
    "\n",
    "# Hourly traffic patterns\n",
    "hourly_traffic = passages_df.groupby(passages_df['timestamp'].dt.hour).size()\n",
    "daily_traffic = passages_df.groupby(passages_df['timestamp'].dt.date).size()\n",
    "\n",
    "# Create traffic pattern visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Traffic Pattern Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Hourly traffic pattern\n",
    "axes[0, 0].plot(hourly_traffic.index, hourly_traffic.values, marker='o', linewidth=2, markersize=6, color='blue')\n",
    "axes[0, 0].set_title('Hourly Traffic Pattern')\n",
    "axes[0, 0].set_xlabel('Hour of Day')\n",
    "axes[0, 0].set_ylabel('Vehicle Count')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].set_xticks(range(0, 24, 2))\n",
    "\n",
    "# Daily traffic pattern\n",
    "axes[0, 1].plot(daily_traffic.index, daily_traffic.values, linewidth=2, color='green')\n",
    "axes[0, 1].set_title('Daily Traffic Volume')\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Vehicle Count')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Weekday pattern\n",
    "weekday_traffic = passages_df.groupby(passages_df['timestamp'].dt.day_name()).size()\n",
    "weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "weekday_traffic = weekday_traffic.reindex([day for day in weekday_order if day in weekday_traffic.index])\n",
    "axes[1, 0].bar(range(len(weekday_traffic)), weekday_traffic.values, color='orange')\n",
    "axes[1, 0].set_title('Traffic by Day of Week')\n",
    "axes[1, 0].set_xlabel('Day of Week')\n",
    "axes[1, 0].set_ylabel('Vehicle Count')\n",
    "axes[1, 0].set_xticks(range(len(weekday_traffic)))\n",
    "axes[1, 0].set_xticklabels([day[:3] for day in weekday_traffic.index], rotation=45)\n",
    "\n",
    "# Speed by hour pattern\n",
    "if 'speed_mph' in passages_df.columns:\n",
    "    hourly_speed = passages_df.groupby(passages_df['timestamp'].dt.hour)['speed_mph'].mean()\n",
    "    axes[1, 1].plot(hourly_speed.index, hourly_speed.values, marker='s', linewidth=2, markersize=6, color='red')\n",
    "    axes[1, 1].set_title('Average Speed by Hour')\n",
    "    axes[1, 1].set_xlabel('Hour of Day')\n",
    "    axes[1, 1].set_ylabel('Average Speed (mph)')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 1].set_xticks(range(0, 24, 2))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Vehicle Type Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze vehicle types\n",
    "vehicle_analysis = passage_analyzer.analyze_vehicle_types(passages_df)\n",
    "\n",
    "print(\"üöõ Vehicle Type Analysis:\")\n",
    "print(\"=\" * 25)\n",
    "print(\"Distribution:\")\n",
    "for vtype, count in vehicle_analysis.get('type_distribution', {}).items():\n",
    "    percentage = vehicle_analysis.get('type_percentages', {}).get(vtype, 0)\n",
    "    print(f\"  {vtype}: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nPeak Hours by Vehicle Type:\")\n",
    "for vtype, hour in vehicle_analysis.get('peak_hours_by_type', {}).items():\n",
    "    print(f\"  {vtype}: {hour}:00\")\n",
    "\n",
    "# Vehicle type analysis by time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Vehicle Type Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Vehicle type distribution\n",
    "type_counts = passages_df['vehicle_type'].value_counts()\n",
    "colors = plt.cm.Set3(np.arange(len(type_counts)))\n",
    "axes[0, 0].pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "axes[0, 0].set_title('Overall Vehicle Type Distribution')\n",
    "\n",
    "# Vehicle type by hour heatmap\n",
    "hourly_types = passages_df.groupby([passages_df['timestamp'].dt.hour, 'vehicle_type']).size().unstack(fill_value=0)\n",
    "im = axes[0, 1].imshow(hourly_types.T, aspect='auto', cmap='YlOrRd')\n",
    "axes[0, 1].set_title('Vehicle Type by Hour Heatmap')\n",
    "axes[0, 1].set_xlabel('Hour of Day')\n",
    "axes[0, 1].set_ylabel('Vehicle Type')\n",
    "axes[0, 1].set_xticks(range(0, 24, 2))\n",
    "axes[0, 1].set_xticklabels(range(0, 24, 2))\n",
    "axes[0, 1].set_yticks(range(len(hourly_types.columns)))\n",
    "axes[0, 1].set_yticklabels(hourly_types.columns)\n",
    "plt.colorbar(im, ax=axes[0, 1], label='Vehicle Count')\n",
    "\n",
    "# Speed distribution by vehicle type\n",
    "if 'speed_mph' in passages_df.columns:\n",
    "    for i, vtype in enumerate(passages_df['vehicle_type'].unique()):\n",
    "        speeds = passages_df[passages_df['vehicle_type'] == vtype]['speed_mph'].dropna()\n",
    "        axes[1, 0].hist(speeds, alpha=0.6, label=vtype, bins=20)\n",
    "    axes[1, 0].set_title('Speed Distribution by Vehicle Type')\n",
    "    axes[1, 0].set_xlabel('Speed (mph)')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "# Average speed by vehicle type\n",
    "if 'speed_mph' in passages_df.columns:\n",
    "    avg_speeds = passages_df.groupby('vehicle_type')['speed_mph'].mean().sort_values(ascending=True)\n",
    "    axes[1, 1].barh(range(len(avg_speeds)), avg_speeds.values, color='lightcoral')\n",
    "    axes[1, 1].set_title('Average Speed by Vehicle Type')\n",
    "    axes[1, 1].set_xlabel('Average Speed (mph)')\n",
    "    axes[1, 1].set_yticks(range(len(avg_speeds)))\n",
    "    axes[1, 1].set_yticklabels(avg_speeds.index)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(avg_speeds.values):\n",
    "        axes[1, 1].text(v + 1, i, f'{v:.1f}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Speed and Flow Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed analysis\n",
    "if 'speed_mph' in passages_df.columns:\n",
    "    print(\"üèéÔ∏è Speed Analysis:\")\n",
    "    print(\"=\" * 17)\n",
    "    print(f\"Average speed: {passages_df['speed_mph'].mean():.1f} mph\")\n",
    "    print(f\"Median speed: {passages_df['speed_mph'].median():.1f} mph\")\n",
    "    print(f\"Speed std dev: {passages_df['speed_mph'].std():.1f} mph\")\n",
    "    print(f\"Min speed: {passages_df['speed_mph'].min():.1f} mph\")\n",
    "    print(f\"Max speed: {passages_df['speed_mph'].max():.1f} mph\")\n",
    "    \n",
    "    # Speed percentiles\n",
    "    percentiles = [10, 25, 50, 75, 85, 95]\n",
    "    print(\"\\nSpeed Percentiles:\")\n",
    "    for p in percentiles:\n",
    "        speed_p = passages_df['speed_mph'].quantile(p/100)\n",
    "        print(f\"  {p}th percentile: {speed_p:.1f} mph\")\n",
    "    \n",
    "    # Speed by weather condition\n",
    "    if 'weather_condition' in passages_df.columns:\n",
    "        print(\"\\nSpeed by Weather Condition:\")\n",
    "        weather_speeds = passages_df.groupby('weather_condition')['speed_mph'].agg(['mean', 'std']).round(1)\n",
    "        print(weather_speeds)\n",
    "\n",
    "# Traffic flow analysis\n",
    "# Calculate hourly volumes\n",
    "hourly_volumes = passages_df.groupby(passages_df['timestamp'].dt.floor('H')).size()\n",
    "print(f\"\\nüö¶ Traffic Flow Analysis:\")\n",
    "print(\"=\" * 26)\n",
    "print(f\"Peak hourly volume: {hourly_volumes.max()} vehicles\")\n",
    "print(f\"Average hourly volume: {hourly_volumes.mean():.1f} vehicles\")\n",
    "print(f\"Minimum hourly volume: {hourly_volumes.min()} vehicles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed and flow visualizations\n",
    "if 'speed_mph' in passages_df.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Speed and Flow Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Speed histogram\n",
    "    axes[0, 0].hist(passages_df['speed_mph'].dropna(), bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0, 0].axvline(passages_df['speed_mph'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {passages_df[\"speed_mph\"].mean():.1f}')\n",
    "    axes[0, 0].axvline(passages_df['speed_mph'].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {passages_df[\"speed_mph\"].median():.1f}')\n",
    "    axes[0, 0].set_title('Speed Distribution')\n",
    "    axes[0, 0].set_xlabel('Speed (mph)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Speed box plot by lane\n",
    "    lane_speeds = [passages_df[passages_df['lane_id'] == lane]['speed_mph'].dropna() for lane in passages_df['lane_id'].unique()]\n",
    "    axes[0, 1].boxplot(lane_speeds, labels=passages_df['lane_id'].unique())\n",
    "    axes[0, 1].set_title('Speed Distribution by Lane')\n",
    "    axes[0, 1].set_xlabel('Lane ID')\n",
    "    axes[0, 1].set_ylabel('Speed (mph)')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Speed vs Time scatter plot\n",
    "    sample_data = passages_df.sample(min(1000, len(passages_df)))  # Sample for performance\n",
    "
